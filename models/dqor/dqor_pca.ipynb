{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-gpu==2.3\n",
    "#!pip install typeguard\n",
    "#!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layers as layers\n",
    "import models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse, sys\n",
    "sys.path.append(\"../../\")\n",
    "from utils.generator import ImageAugmentationSequenceH5\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import argparse, sys\n",
    "sys.path.append(\"../../\")\n",
    "from utils.generator import ImageAugmentationSequenceH5\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the base xception model\n",
    "\n",
    "input_tensor = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "base_params = {\"weights\": \"imagenet\", \"input_tensor\": input_tensor, \"include_top\": False, \"pooling\": \"avg\"}\n",
    "\n",
    "preprop = tf.keras.applications.xception.preprocess_input\n",
    "base = tf.keras.applications.xception.Xception(**base_params)\n",
    "train_batch = 32\n",
    "val_batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation set up\n",
    "\n",
    "augmentation = {\"preprocessing_function\": preprop, \"apply\":True,\n",
    "                    \"random_brightness\": {\"max_delta\": 0.3},\n",
    "                    \"random_contrast\": {\"lower\":0.7, \"upper\":1},\n",
    "                    \"random_hue\": {\"max_delta\": 0.1},\n",
    "                    \"random_saturation\": {\"lower\": 0.7, \"upper\":1},\n",
    "                    \"random_rotation\": {\"minval\": 0, \"maxval\": 2*np.pi},\n",
    "                    \"horizontal_flip\": True, \"vertical_flip\": True\n",
    "                   }\n",
    "\n",
    "\n",
    "train_seq = ImageAugmentationSequenceH5('/home/stoledoc/work/data1/images.h5', \"ims_train\", \"y_train\", num_classes=5,\n",
    "                                        #labels_transform=lambda i:np.int32(i>1),\n",
    "                                        #labels_transform=lambda i:np.eye(5)[i],\n",
    "                                        class_weighted=False, categorical=False, batch_size=train_batch,\n",
    "                                        #shuffle=True)\n",
    "                                        augmentation = augmentation, shuffle=True)\n",
    "\n",
    "augmentation = {\"preprocessing_function\": preprop, \"apply\":False}\n",
    "\n",
    "val_seq = ImageAugmentationSequenceH5('/home/stoledoc/work/data1/images.h5', \"ims_val\", \"y_val\", num_classes=5,\n",
    "                                      #labels_transform=lambda i:np.int32(i>1),\n",
    "                                      #labels_transform=lambda i:np.eye(5)[i],\n",
    "                                      class_weighted=False, categorical=False, batch_size=val_batch,\n",
    "                                      #shuffle=False)\n",
    "                                      augmentation = augmentation, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Checkpoint for warming up\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath='/home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_warming_up_2.h5', monitor=\"val_loss\", \n",
    "                                              verbose=True, save_best_only=True,\n",
    "                                              save_weights_only=True, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QMR model layers set up\n",
    "\n",
    "fm_x = layers.QFeatureMapRFF(\n",
    "                            input_dim=2048,\n",
    "                            dim=1024, \n",
    "                            gamma=0.0006740385616590121, \n",
    "                            random_state=1)\n",
    "qm = layers.QMeasureClassifEig(dim_x=1024, dim_y=5, num_eig=32)\n",
    "\n",
    "dmregress = layers.DensityMatrixRegression()\n",
    "\n",
    "dm2dist = layers.DensityMatrix2Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QMR layers\n",
    "\n",
    "psi_x = fm_x(base.output)\n",
    "rho_y = qm(psi_x)\n",
    "output = dmregress(rho_y)\n",
    "output_2 = dm2dist(rho_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final model\n",
    "\n",
    "#Freezing the layers for warming up:\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=[output_2, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QMR loss\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    \n",
    "    #print('llegue al loss')\n",
    "    #tf.print(y_true)\n",
    "    return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]*4) + 0.5526216196078314 * y_pred[:, 1:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss=loss, optimizer=tf.optimizers.Adam(lr=0.0001947103376276921))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading weights from JSLara\n",
    "\n",
    "model.load_weights('models/xception.h5', by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 127, 127, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 127, 127, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 125, 125, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 125, 125, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 125, 125, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 125, 125, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 125, 125, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 125, 125, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 125, 125, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 63, 63, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 63, 63, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 63, 63, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 63, 63, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 63, 63, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 63, 63, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 63, 63, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 63, 63, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 63, 63, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 32, 32, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 32, 32, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 32, 32, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 16, 16, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 16, 16, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 16, 16, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 16, 16, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 16, 16, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 16, 16, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 16, 16, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 16, 16, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 16, 16, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 16, 16, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 16, 16, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 16, 16, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 16, 16, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 16, 16, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 16, 16, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 16, 16, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 16, 16, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 16, 16, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 16, 16, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 16, 16, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 16, 16, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 16, 16, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 16, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 16, 16, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 8, 8, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 8, 8, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 8, 8, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 8, 8, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 8, 8, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 8, 8, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 8, 8, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "q_feature_map_rff (QFeatureMapR (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "q_measure_classif_eig (QMeasure (None, 5, 5)         163872      q_feature_map_rff[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "density_matrix_regression (Dens (None, 2)            0           q_measure_classif_eig[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 23,123,528\n",
      "Trainable params: 2,262,048\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/image/transform_ops.py:143: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.\n",
      "  \"fill_value is not supported and is always 0 for TensorFlow < 2.4.0.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.5725\n",
      "Epoch 00001: val_loss improved from inf to 0.92496, saving model to /home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_warming_up_2.h5\n",
      "8397/8397 [==============================] - 3904s 465ms/step - loss: 0.5725 - val_loss: 0.9250\n",
      "Epoch 2/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.5236\n",
      "Epoch 00002: val_loss did not improve from 0.92496\n",
      "8397/8397 [==============================] - 4137s 493ms/step - loss: 0.5236 - val_loss: 0.9392\n",
      "Epoch 3/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4986\n",
      "Epoch 00003: val_loss improved from 0.92496 to 0.91714, saving model to /home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_warming_up_2.h5\n",
      "8397/8397 [==============================] - 4122s 491ms/step - loss: 0.4986 - val_loss: 0.9171\n",
      "Epoch 4/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4834\n",
      "Epoch 00004: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 4119s 491ms/step - loss: 0.4834 - val_loss: 0.9294\n",
      "Epoch 5/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4737\n",
      "Epoch 00005: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 4122s 491ms/step - loss: 0.4737 - val_loss: 0.9311\n",
      "Epoch 6/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4659\n",
      "Epoch 00006: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 4125s 491ms/step - loss: 0.4659 - val_loss: 0.9324\n",
      "Epoch 7/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4559\n",
      "Epoch 00007: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 3758s 448ms/step - loss: 0.4559 - val_loss: 0.9482\n",
      "Epoch 8/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4520\n",
      "Epoch 00008: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2891s 344ms/step - loss: 0.4520 - val_loss: 0.9770\n",
      "Epoch 9/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4467\n",
      "Epoch 00009: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2891s 344ms/step - loss: 0.4467 - val_loss: 0.9526\n",
      "Epoch 10/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4410\n",
      "Epoch 00010: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2893s 345ms/step - loss: 0.4410 - val_loss: 0.9532\n",
      "Epoch 11/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4375\n",
      "Epoch 00011: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2891s 344ms/step - loss: 0.4375 - val_loss: 0.9624\n",
      "Epoch 12/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4351\n",
      "Epoch 00012: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2893s 345ms/step - loss: 0.4351 - val_loss: 0.9553\n",
      "Epoch 13/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4317\n",
      "Epoch 00013: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2893s 345ms/step - loss: 0.4317 - val_loss: 0.9393\n",
      "Epoch 14/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4284\n",
      "Epoch 00014: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2891s 344ms/step - loss: 0.4284 - val_loss: 0.9756\n",
      "Epoch 15/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4279\n",
      "Epoch 00015: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2892s 344ms/step - loss: 0.4279 - val_loss: 0.9456\n",
      "Epoch 16/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4241\n",
      "Epoch 00016: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2891s 344ms/step - loss: 0.4241 - val_loss: 0.9621\n",
      "Epoch 17/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4213\n",
      "Epoch 00017: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2892s 344ms/step - loss: 0.4213 - val_loss: 0.9579\n",
      "Epoch 18/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4202\n",
      "Epoch 00018: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2894s 345ms/step - loss: 0.4202 - val_loss: 0.9789\n",
      "Epoch 19/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4148\n",
      "Epoch 00019: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2893s 344ms/step - loss: 0.4148 - val_loss: 0.9738\n",
      "Epoch 20/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4163\n",
      "Epoch 00020: val_loss did not improve from 0.91714\n",
      "8397/8397 [==============================] - 2891s 344ms/step - loss: 0.4163 - val_loss: 0.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff8b2e5c450>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_seq, steps_per_epoch=len(train_seq), validation_data=val_seq, validation_steps=len(val_seq),\n",
    "          epochs=20, callbacks=[callback], shuffle=True, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UnFreezing the layers after warming up:\n",
    "for layer in base.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.compile(loss=loss, optimizer=tf.optimizers.Adam(lr=1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_warming_up_2.h5', by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Checkpoint for Full train\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath='/home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_full_train_3.h5', monitor=\"val_loss\", \n",
    "                                              verbose=True, save_best_only=True,\n",
    "                                              save_weights_only=True, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/image/transform_ops.py:143: UserWarning: fill_value is not supported and is always 0 for TensorFlow < 2.4.0.\n",
      "  \"fill_value is not supported and is always 0 for TensorFlow < 2.4.0.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   2/8397 [..............................] - ETA: 1:00:22 - loss: 0.4505WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1692s vs `on_train_batch_end` time: 0.6917s). Check your callbacks.\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.5068\n",
      "Epoch 00001: val_loss improved from inf to 0.91710, saving model to /home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_full_train_3.h5\n",
      "8397/8397 [==============================] - 9329s 1s/step - loss: 0.5068 - val_loss: 0.9171\n",
      "Epoch 2/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4955\n",
      "Epoch 00002: val_loss improved from 0.91710 to 0.91411, saving model to /home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_full_train_3.h5\n",
      "8397/8397 [==============================] - 9309s 1s/step - loss: 0.4955 - val_loss: 0.9141\n",
      "Epoch 3/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4899\n",
      "Epoch 00003: val_loss improved from 0.91411 to 0.91251, saving model to /home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_full_train_3.h5\n",
      "8397/8397 [==============================] - 9262s 1s/step - loss: 0.4899 - val_loss: 0.9125\n",
      "Epoch 4/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4866\n",
      "Epoch 00004: val_loss did not improve from 0.91251\n",
      "8397/8397 [==============================] - 9318s 1s/step - loss: 0.4866 - val_loss: 0.9139\n",
      "Epoch 5/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4813\n",
      "Epoch 00005: val_loss improved from 0.91251 to 0.90929, saving model to /home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_full_train_3.h5\n",
      "8397/8397 [==============================] - 9307s 1s/step - loss: 0.4813 - val_loss: 0.9093\n",
      "Epoch 6/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4806\n",
      "Epoch 00006: val_loss did not improve from 0.90929\n",
      "8397/8397 [==============================] - 9305s 1s/step - loss: 0.4806 - val_loss: 0.9104\n",
      "Epoch 7/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4772\n",
      "Epoch 00007: val_loss improved from 0.90929 to 0.90830, saving model to /home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_full_train_3.h5\n",
      "8397/8397 [==============================] - 9312s 1s/step - loss: 0.4772 - val_loss: 0.9083\n",
      "Epoch 8/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4750\n",
      "Epoch 00008: val_loss did not improve from 0.90830\n",
      "8397/8397 [==============================] - 9323s 1s/step - loss: 0.4750 - val_loss: 0.9115\n",
      "Epoch 9/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4704\n",
      "Epoch 00009: val_loss did not improve from 0.90830\n",
      "8397/8397 [==============================] - 9300s 1s/step - loss: 0.4704 - val_loss: 0.9084\n",
      "Epoch 10/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4688\n",
      "Epoch 00010: val_loss did not improve from 0.90830\n",
      "8397/8397 [==============================] - 9320s 1s/step - loss: 0.4688 - val_loss: 0.9106\n",
      "Epoch 11/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4670\n",
      "Epoch 00011: val_loss did not improve from 0.90830\n",
      "8397/8397 [==============================] - 9302s 1s/step - loss: 0.4670 - val_loss: 0.9117\n",
      "Epoch 12/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4658\n",
      "Epoch 00012: val_loss improved from 0.90830 to 0.90736, saving model to /home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_full_train_3.h5\n",
      "8397/8397 [==============================] - 9300s 1s/step - loss: 0.4658 - val_loss: 0.9074\n",
      "Epoch 13/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4657\n",
      "Epoch 00013: val_loss did not improve from 0.90736\n",
      "8397/8397 [==============================] - 9305s 1s/step - loss: 0.4657 - val_loss: 0.9121\n",
      "Epoch 14/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4600\n",
      "Epoch 00014: val_loss did not improve from 0.90736\n",
      "8397/8397 [==============================] - 9306s 1s/step - loss: 0.4600 - val_loss: 0.9093\n",
      "Epoch 15/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4615\n",
      "Epoch 00015: val_loss did not improve from 0.90736\n",
      "8397/8397 [==============================] - 9309s 1s/step - loss: 0.4615 - val_loss: 0.9127\n",
      "Epoch 16/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4582\n",
      "Epoch 00016: val_loss did not improve from 0.90736\n",
      "8397/8397 [==============================] - 9307s 1s/step - loss: 0.4582 - val_loss: 0.9104\n",
      "Epoch 17/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4546\n",
      "Epoch 00017: val_loss did not improve from 0.90736\n",
      "8397/8397 [==============================] - 9316s 1s/step - loss: 0.4546 - val_loss: 0.9128\n",
      "Epoch 18/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4537\n",
      "Epoch 00018: val_loss did not improve from 0.90736\n",
      "8397/8397 [==============================] - 9301s 1s/step - loss: 0.4537 - val_loss: 0.9149\n",
      "Epoch 19/20\n",
      "8397/8397 [==============================] - ETA: 0s - loss: 0.4544\n",
      "Epoch 00019: val_loss did not improve from 0.90736\n",
      "8397/8397 [==============================] - 9307s 1s/step - loss: 0.4544 - val_loss: 0.9181\n",
      "Epoch 20/20\n",
      "3537/8397 [===========>..................] - ETA: 1:23:28 - loss: 0.4525"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bde873b453b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train_seq, steps_per_epoch=len(train_seq), validation_data=val_seq, validation_steps=len(val_seq),\n\u001b[0;32m----> 2\u001b[0;31m           epochs=20, callbacks=[callback], shuffle=True, use_multiprocessing=False)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_seq, steps_per_epoch=len(train_seq), validation_data=val_seq, validation_steps=len(val_seq),\n",
    "          epochs=20, callbacks=[callback], shuffle=True, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "file_route = '/home/stoledoc/work/data1/images.h5'\n",
    "\n",
    "with h5py.File(file_route,'r') as h5:\n",
    "\n",
    "    \n",
    "    #X_train = h5['ims_train'].value\n",
    "    #X_val = h5['ims_val'].value\n",
    "    X_test = h5['ims_test'].value\n",
    "    \n",
    "    #y_train = h5['y_train'].value\n",
    "    #y_val = h5['y_val'].value\n",
    "    y_test = h5['y_test'].value\n",
    "    #id_ims_train = h5['id_train'].value\n",
    "    #id_ims_val = h5['id_val'].value\n",
    "    id_ims_test = h5['id_test'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading weights \n",
    "\n",
    "model.load_weights('/home/stoledoc/work/datanfs/stoledoc/MICCAI_2021/xception+qmr_full_train_3.h5')#, by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = {\"preprocessing_function\": preprop, \"apply\":False}\n",
    "\n",
    "test_seq = ImageAugmentationSequenceH5('/home/stoledoc/work/data1/images.h5', \"ims_test\", \"y_test\", num_classes=5,\n",
    "                                       #labels_transform=lambda i:np.int32(i>1), \n",
    "                                       return_y=False,\n",
    "                                       class_weighted=False, categorical=False, batch_size=20,\n",
    "                                       augmentation = augmentation, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/4387 [..............................] - ETA: 3:55WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0137s vs `on_predict_batch_end` time: 0.1095s). Check your callbacks.\n",
      "4387/4387 [==============================] - 460s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(test_seq, steps=len(test_seq), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87740, 5), (87740, 2))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape, out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87740, 5), (87740, 2))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape, out[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta evaluaciòn tomamos el modelo que bota solo el mean y el std. Pilas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  roc_curve, roc_auc_score, classification_report, confusion_matrix, accuracy_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, std = out[1][:, 0], np.sqrt(out[1][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6660456 , 0.46914953, 0.6110195 , ..., 0.49020052, 0.27564344,\n",
       "       0.63827837], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4], dtype=uint8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------MAE = 0.87410533\n"
     ]
    }
   ],
   "source": [
    "print('------------MAE =', mean_absolute_error(y_test, np.rint(y_pred*4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1527    0.0997    0.1207      7640\n",
      "           1     0.6630    0.4249    0.5179     32302\n",
      "           2     0.2536    0.4742    0.3305     15301\n",
      "           3     0.4304    0.4707    0.4497     30560\n",
      "           4     0.0000    0.0000    0.0000      1937\n",
      "\n",
      "    accuracy                         0.4118     87740\n",
      "   macro avg     0.3000    0.2939    0.2837     87740\n",
      "weighted avg     0.4515    0.4118    0.4154     87740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, np.rint(y_pred*4), digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Level: Mayority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.rint(y_pred*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(set(id_ims_test))\n",
    "keys.sort()\n",
    "#keys = list(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_0 = {} \n",
    "  \n",
    "for i in keys: \n",
    "    d_0[i] = 0\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "  if y_pred[i] == 0:\n",
    "    d_0[id_ims_test[i]] += 1\n",
    "\n",
    "d_1 = {} \n",
    "  \n",
    "for i in keys: \n",
    "    d_1[i] = 0\n",
    "\n",
    "for i in range(id_ims_test.shape[0]):\n",
    "  if y_pred[i] == 1:\n",
    "    d_1[id_ims_test[i]] += 1\n",
    "\n",
    "d_2 = {} \n",
    "  \n",
    "for i in keys: \n",
    "    d_2[i] = 0\n",
    "\n",
    "for i in range(id_ims_test.shape[0]):\n",
    "  if y_pred[i] == 2:\n",
    "    d_2[id_ims_test[i]] += 1\n",
    "\n",
    "d_3 = {} \n",
    "  \n",
    "for i in keys: \n",
    "    d_3[i] = 0\n",
    "\n",
    "for i in range(id_ims_test.shape[0]):\n",
    "  if y_pred[i] == 3:\n",
    "    d_3[id_ims_test[i]] += 1\n",
    "\n",
    "d_4 = {} \n",
    "  \n",
    "for i in keys: \n",
    "    d_4[i] = 0\n",
    "\n",
    "for i in range(id_ims_test.shape[0]):\n",
    "  if y_pred[i] == 4:\n",
    "    d_4[id_ims_test[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_pred = []\n",
    "\n",
    "for i in range(len(keys)):\n",
    "  vote = np.argmax([d_0[keys[i]], d_1[keys[i]], d_2[keys[i]], d_3[keys[i]], d_4[keys[i]]])\n",
    "  vote_pred.append(vote)\n",
    "\n",
    "vote_pred = np.asarray(vote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_0 = {} \n",
    "  \n",
    "for i in keys: \n",
    "    d_0[i] = 0\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "  if y_test[i] == 0:\n",
    "    d_0[id_ims_test[i]] += 1\n",
    "\n",
    "d_1 = {} \n",
    "  \n",
    "for i in keys: \n",
    "    d_1[i] = 0\n",
    "\n",
    "for i in range(id_ims_test.shape[0]):\n",
    "  if y_test[i] == 1:\n",
    "    d_1[id_ims_test[i]] += 1\n",
    "\n",
    "d_2 = {} \n",
    "  \n",
    "for i in keys: \n",
    "    d_2[i] = 0\n",
    "\n",
    "for i in range(id_ims_test.shape[0]):\n",
    "  if y_test[i] == 2:\n",
    "    d_2[id_ims_test[i]] += 1\n",
    "\n",
    "d_3 = {} \n",
    "  \n",
    "for i in keys: \n",
    "    d_3[i] = 0\n",
    "\n",
    "for i in range(id_ims_test.shape[0]):\n",
    "  if y_test[i] == 3:\n",
    "    d_3[id_ims_test[i]] += 1\n",
    "\n",
    "d_4 = {} \n",
    "  \n",
    "for i in keys: \n",
    "    d_4[i] = 0\n",
    "\n",
    "for i in range(id_ims_test.shape[0]):\n",
    "  if y_test[i] == 4:\n",
    "    d_4[id_ims_test[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_test = []\n",
    "\n",
    "for i in range(len(keys)):\n",
    "  vote = np.argmax([d_0[keys[i]], d_1[keys[i]], d_2[keys[i]], d_3[keys[i]], d_4[keys[i]]])\n",
    "  vote_test.append(vote)\n",
    "\n",
    "vote_test = np.asarray(vote_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 1, 1,\n",
       "       4, 2, 3, 3, 3, 1, 2, 2, 0, 2, 0, 2, 2, 2, 3, 3, 2, 1, 3, 3, 0, 3,\n",
       "       3, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------MAE = 0.6304347826086957\n"
     ]
    }
   ],
   "source": [
    "print('------------MAE =', mean_absolute_error(vote_test, vote_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         4\n",
      "           1     0.9231    0.7059    0.8000        17\n",
      "           2     0.2778    0.6250    0.3846         8\n",
      "           3     0.5333    0.5000    0.5161        16\n",
      "           4     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5435        46\n",
      "   macro avg     0.3468    0.3662    0.3401        46\n",
      "weighted avg     0.5750    0.5435    0.5421        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(vote_test, vote_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  3  1  0]\n",
      " [ 0 12  3  2  0]\n",
      " [ 0  0  5  3  0]\n",
      " [ 0  1  7  8  0]\n",
      " [ 0  0  0  1  0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(vote_test, vote_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Level: Probability Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_pred = out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dist_pred = {}\n",
    "for i in keys: \n",
    "    dict_dist_pred[i] = [0, 0, 0, 0, 0] # Initializing a null distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    dict_dist_pred[id_ims_test[i]] = dict_dist_pred[id_ims_test[i]] + dist_pred[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just picking the argmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pred = []\n",
    "\n",
    "for i in range(len(keys)):\n",
    "  prob = np.argmax(dict_dist_pred[keys[i]])\n",
    "  prob_pred.append(prob)\n",
    "\n",
    "prob_pred = np.asarray(prob_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3,\n",
       "       3, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------MAE = 0.717391304347826\n"
     ]
    }
   ],
   "source": [
    "print('------------MAE =', mean_absolute_error(vote_test, prob_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         4\n",
      "           1     0.7368    0.8235    0.7778        17\n",
      "           2     0.5000    0.3750    0.4286         8\n",
      "           3     0.4762    0.6250    0.5405        16\n",
      "           4     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5870        46\n",
      "   macro avg     0.3426    0.3647    0.3494        46\n",
      "weighted avg     0.5249    0.5870    0.5500        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(vote_test, prob_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  1  3  0]\n",
      " [ 0 14  1  2  0]\n",
      " [ 0  0  3  5  0]\n",
      " [ 0  5  1 10  0]\n",
      " [ 0  0  0  1  0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(vote_test, prob_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now computing the expected value and setting it as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0,1,2,3,4]\n",
    "E_pred = []\n",
    "for i in range(len(keys)):\n",
    "  dist = dict_dist_pred[keys[i]]/np.sum(dict_dist_pred[keys[i]])\n",
    "  prediction = np.rint(np.dot(dist, labels))\n",
    "  E_pred.append(prediction)\n",
    "E_pred = np.asarray(E_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 2., 1., 1., 2., 2., 2., 1., 1., 1., 1., 1., 2., 2., 2., 1.,\n",
       "       1., 2., 2., 1., 1., 2., 2., 3., 3., 2., 2., 2., 3., 2., 2., 3., 2.,\n",
       "       2., 2., 3., 2., 3., 3., 2., 3., 2., 3., 3., 3.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------MAE = 0.6521739130434783\n"
     ]
    }
   ],
   "source": [
    "print('------------MAE =', mean_absolute_error(vote_test, E_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         4\n",
      "           1     1.0000    0.6471    0.7857        17\n",
      "           2     0.2609    0.7500    0.3871         8\n",
      "           3     0.5833    0.4375    0.5000        16\n",
      "           4     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.5217        46\n",
      "   macro avg     0.3688    0.3669    0.3346        46\n",
      "weighted avg     0.6178    0.5217    0.5316        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(vote_test, E_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  3  1  0]\n",
      " [ 0 11  4  2  0]\n",
      " [ 0  0  6  2  0]\n",
      " [ 0  0  9  7  0]\n",
      " [ 0  0  1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(vote_test, E_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
